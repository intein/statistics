{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезная страница\n",
    "http://statsmodels.sourceforge.net/devel/stats.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интервальная оценка среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import _zconfint_generic, _tconfint_generic, zconfint\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('95%% confidence interval for the mean time: [%f, %f]' % zconfint(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_zconfint_generic(Выборочное среднее, стандартная ошибка среднего(Станд. откл./Корень из объема выборки), Альфа(0.05), 'two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_tconfint_generic(Выборочное среднее, стандартная ошибка среднего, Кол-во степеней свободы (n - 1), 0.05, 'two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zconfint(data.Placebo) - интервальная оценка среднего по выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t пригодится тогда, когда мы изначально не знаем, какая дисперсия в генеральной совокупности. z можно применять для выборок с N>30, потому что ЦПТ порождает нормальное распределение выборочного среднего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доверительный интервал для доли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_interval = proportion_confint(sum(random_sample), len(random_sample), method = 'normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wilson_interval = proportion_confint(sum(random_sample), len(random_sample), method = 'wilson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Интервал Уилсона лучше. Особенно когда случайная подвыборка мала. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Проверка гипотезы о равенстве долей: хи-квадрат:\n",
    "stats.chi2_contingency(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Размер выборки для интервала заданной ширины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import samplesize_confint_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = int(np.ceil(samplesize_confint_proportion(sample.mean(), половина нужной нам ширины интервала)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доверительные интервалы для разности долей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.proportion import proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportions_confint_diff_ind(sample1, sample2, alpha = 0.05):    \n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)   \n",
    "    p1 = float(sum(sample1)) / len(sample1)\n",
    "    p2 = float(sum(sample2)) / len(sample2)\n",
    "    \n",
    "    left_boundary = (p1 - p2) - z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    right_boundary = (p1 - p2) + z * np.sqrt(p1 * (1 - p1)/ len(sample1) + p2 * (1 - p2)/ len(sample2))\n",
    "    \n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Доверительные интервалы для разности долей (связанные выборки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportions_confint_diff_rel(sample1, sample2, alpha = 0.05):\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    sample = list(zip(sample1, sample2))\n",
    "    n = len(sample)\n",
    "        \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    left_boundary = float(f - g) / n  - z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    right_boundary = float(f - g) / n  + z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доверительные интервалы на основе бутстрепа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples):\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples\n",
    "    \n",
    "Есть вариант в виде итератора, чтобы не держать в памяти огромный массив\n",
    "def get_bootstrap_samples(data, n_samples):\n",
    "    i = 0\n",
    "    while i < n_samples:\n",
    "        indices = np.random.randint(0, len(data), len(data))\n",
    "        sample = data[indices]\n",
    "        yield sample\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Интервальная оценка медианы\n",
    "sample_median_scores = list(map(np.median, get_bootstrap_samples(sample, 1000)))\n",
    "stat_intervals(sample_median_scores, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Интервальная оценка разности медиан\n",
    "delta_median_scores = list(map(lambda x: x[1] - x[0], zip(sample1_median_scores, sample2_median_scores)))\n",
    "stat_intervals(delta_median_scores, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Одновыборочный критерий Стьюдента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from statsmodels.stats.weightstats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.ttest_1samp(data.Placebo, 50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zconfint(data.Placebo) - интервальная оценка среднего по выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на нормальность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QQ-плот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,2,1)\n",
    "stats.probplot(lech.ix[:, 1], dist=\"norm\", plot=plt)\n",
    "plt.subplot(2,2,2)\n",
    "stats.probplot(ped.ix[:, 1], dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Критерий Шапиро - Уилка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.shapiro(data.Placebo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двухвыборочный критерий Стьюдента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут надо помнить, что генеральные дисперсии должны быть одинаковы (проблема Беренса-Фишера). \n",
    "Но мы, как правило, не обладаем подобной инфой, так что над прописывать equal_var=False, чтобы использовать t-критерий Уэлша (и вообще лучше всегда его юзать). \n",
    "Если так уж надо будет, сравнивать дисперсии хорошо через scipy.stats.levene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(data.Placebo, data.Methylphenidate, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = CompareMeans(DescrStatsW(data.Methylphenidate), DescrStatsW(data.Placebo))\n",
    "cm.tconfint_diff(usevar='unequal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#И для связанных выборок\n",
    "stats.ttest_rel(data.Methylphenidate, data.Placebo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DescrStatsW(data.Methylphenidate - data.Placebo).tconfint_mean() - доверительный интервал разности для связанных выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Z-критерий для разности долей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_ind(sample1, sample2):\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proportions_diff_z_test(proportions_diff_z_stat_ind(sample1, sample2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для связанных выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_rel(sample1, sample2):\n",
    "    sample = list(zip(sample1, sample2))\n",
    "    n = len(sample)\n",
    "    \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    return float(f - g) / np.sqrt(f + g - float((f - g)**2) / n )\n",
    "    \n",
    "#Реализация расчета p-value двумя ячейками выше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " proportions_diff_z_test(proportions_diff_z_stat_rel(data.banner_a, data.banner_b), 'less'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Одновыборочный критерий знаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"M: %d, p-value: %f\" % sign_test(sample, медиана))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Одновыборочный критерий знаковых рангов Вилкоксона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m0 = 0.5\n",
    "stats.wilcoxon(sample - m0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Одновыборочный перестановочный критерий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Считаем t-статистику\n",
    "def permutation_t_stat_1sample(sample, mean):\n",
    "    t_stat = sum(list(map(lambda x: x - mean, sample)))\n",
    "    return t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Генерация выборок с возможными перестановками знаков, дабы восстановить распределение\n",
    "def permutation_zero_distr_1sample(sample, mean, max_permutations = None):\n",
    "    centered_sample = list(map(lambda x: x - mean, sample))\n",
    "    if max_permutations:\n",
    "        signs_array = set([tuple(x) for x in 2 * np.random.randint(2, size = (max_permutations, \n",
    "                                                                              len(sample))) - 1 ])\n",
    "    else:\n",
    "        signs_array =  itertools.product([-1, 1], repeat = len(sample))\n",
    "    distr = [sum(centered_sample * np.array(signs)) for signs in signs_array]\n",
    "    return distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.hist(permutation_zero_distr_1sample(mouses_data.proportion_of_time, (среднее, с которым сравнить), bins = 15)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Считаем p-value\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_1sample(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_distr_1sample(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"p-value: %f\" % permutation_test(выборка, среднее, количество перестановок(например,10000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двухвыборочный критерий знаков для связанных выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sign_test(sample1 - sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двухвыборочный критерий знаковых рангов Вилкоксона для связанных выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.wilcoxon(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двухвыборочный перестановочный критерий для связанных выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Все то же самое, что мы делали с одновыборочным. Вычисляем t-статистику\n",
    "def permutation_t_stat_1sample(sample, mean):\n",
    "    t_stat = sum(map(lambda x: x - mean, sample))\n",
    "    return t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Считаем нулевое распределение\n",
    "def permutation_zero_distr_1sample(sample, mean, max_permutations = None):\n",
    "    centered_sample = list(map(lambda x: x - mean, sample))\n",
    "    if max_permutations:\n",
    "        signs_array = set([tuple(x) for x in 2 * np.random.randint(2, size = (max_permutations, \n",
    "                                                                              len(sample))) - 1 ])\n",
    "    else:\n",
    "        signs_array =  itertools.product([-1, 1], repeat = len(sample))\n",
    "    distr = [sum(centered_sample * np.array(signs)) for signs in signs_array]\n",
    "    return distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Можно сразу посмотреть на нулевое распределение\n",
    "pylab.hist(permutation_zero_distr_1sample(weight_data.After - weight_data.Before, 0., \n",
    "                               max_permutations = 10000))\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ну и считаем p-value\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_1sample(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_distr_1sample(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"p-value: %f\" % permutation_test(weight_data.After - weight_data.Before, 0., \n",
    "                               max_permutations = 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае критерия знаков под средним мы понимаем медиану. В случае перестановочного -- матожидание разности. Знаковые критерии используют только знаки перед значениями, не учитывает абсолютные значения. Ранговые критерии используют порядки. Перестановочный критерий использует гораздо больше информации, поскольку учитывает значения. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ранговый критерий Манна-Уитни для независимых выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.mannwhitneyu(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перестановочный критерий для независмых выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permutation_t_stat_ind(sample1, sample2):\n",
    "    return np.mean(sample1) - np.mean(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_combinations(n1, n2, max_combinations):\n",
    "    index = list(range(n1 + n2))\n",
    "    indices = set([tuple(index)])\n",
    "    for i in range(max_combinations - 1):\n",
    "        np.random.shuffle(index)\n",
    "        indices.add(tuple(index))\n",
    "    return [(index[:n1], index[n1:]) for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permutation_zero_dist_ind(sample1, sample2, max_combinations = None):\n",
    "    joined_sample = np.hstack((sample1, sample2))\n",
    "    n1 = len(sample1)\n",
    "    n = len(joined_sample)\n",
    "    \n",
    "    if max_combinations:\n",
    "        indices = get_random_combinations(n1, len(sample2), max_combinations)\n",
    "    else:\n",
    "        indices = [(list(index), filter(lambda i: i not in index, range(n))) \\\n",
    "                    for index in itertools.combinations(range(n), n1)]\n",
    "    \n",
    "    distr = [joined_sample[list(i[0])].mean() - joined_sample[list(i[1])].mean() \\\n",
    "             for i in indices]\n",
    "    return distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pylab.hist(permutation_zero_dist_ind(price2001, price2002, max_combinations = 1000))\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_ind(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_dist_ind(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"p-value: %f\" % permutation_test(price2001, price2002, max_permutations = 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Корреляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DataFrame.corr(method='spearman')\n",
    "\n",
    "Можно использовать это:\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Критерии для проверки значимости корреляции: \n",
    "- Критерий Стьюдента для корреляции Пирсона и Спирмена\n",
    "- Критерий хи-квадрат для корреляции Мэтьюса и коэффициента V Крамера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Корреляция Мэтьюса:\n",
    "def matthews_coeff(a, b, c, d):\n",
    "    \"\"\"Calculates Matthew's correlation coefficient of a given contingency table [a, b], [c, d]\n",
    "    (https://en.wikipedia.org/wiki/Matthews_correlation_coefficient).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        a : integer, negative value count of the first binary feature.\n",
    "        b : integer, positive value count of the first binary feature.\n",
    "        c : integer, negative value count of the second binary feature.\n",
    "        d : integer, positive value count of the second binary feature.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        coeff : float, -1 <= coeff <= 1.\n",
    "        \"\"\"\n",
    "    assert all([a, b, c, d]) >= 0, 'arguments can not be less than zero'\n",
    "    return float(a * d - b * c) / np.sqrt((a + b) * (a + c) * (b + d) * (c + d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Коэффициент Крамера:\n",
    "def cramers_coeff(table):\n",
    "    \"\"\"Calculates Cramer's coefficient of a given contingency table (https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        table : array-like, displays the (multivariate) frequency distribution of the variables.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        coeff : float, 0 <= coeff <= 1.\n",
    "        \"\"\"\n",
    "    chi2 = sts.chi2_contingency(table)[0]\n",
    "    n = table.sum()\n",
    "    return np.sqrt(chi2 / (n*(min(table.shape)-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Поправка на множественную проверку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Метод Холма:\n",
    "reject, p_corrected, a1, a2 = multipletests(sales_correlation.p, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'holm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Метод Бенджамини - Хохберга:\n",
    "reject, p_corrected, a1, a2 = multipletests(sales_correlation.p, \n",
    "                                            alpha = 0.05, \n",
    "                                            method = 'fdr_bh') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стало быть, мы передаем список p-значений, нужный нам уровень значимости и метод. \n",
    "Получаем ответ, отклонить ли нам нулевую гипотезу, а также скоррективрованное значение р. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
